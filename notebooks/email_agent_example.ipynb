{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 18:30:21,563\tINFO worker.py:1783 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "import cloudpickle\n",
    "import pickle\n",
    "import collections\n",
    "import ray\n",
    "import threading\n",
    "import hmac\n",
    "\n",
    "def serialize_sqlite_connection(conn):\n",
    "    return ray.data.datasource\n",
    "\n",
    "def deserialize_sqlite_connection(path):\n",
    "    return sqlite3.connect(path)\n",
    "\n",
    "def serialize_thread_lock(lock):\n",
    "    print(\"serialized_thread_lock\")\n",
    "    return None\n",
    "\n",
    "def deserialize_thread_lock(_):\n",
    "    return None\n",
    "\n",
    "class SerializableHMAC:\n",
    "    def __init__(self, hmac_obj):\n",
    "        self.msg = hmac_obj.digest()\n",
    "        self.digestmod = hmac_obj.digest_size\n",
    "\n",
    "    @classmethod\n",
    "    def from_hmac(cls, hmac_obj):\n",
    "        return cls(hmac_obj)\n",
    "\n",
    "    def to_hmac(self):\n",
    "        return hmac.new(b'', self.msg, digestmod=self.digestmod)\n",
    "\n",
    "def serialize_hmac(hmac_obj):\n",
    "    return SerializableHMAC.from_hmac(hmac_obj)\n",
    "\n",
    "def deserialize_hmac(serialized_hmac):\n",
    "    return serialized_hmac.to_hmac()\n",
    "\n",
    "class HandleWrapper:\n",
    "    def __init__(self, obj):\n",
    "        self.class_name = type(obj).__name__\n",
    "        self.attributes = {}\n",
    "        for key, value in obj.__dict__.items():\n",
    "            if not key.startswith('_'):\n",
    "                try:\n",
    "                    cloudpickle.dumps(value)\n",
    "                    self.attributes[key] = value\n",
    "                except:\n",
    "                    self.attributes[key] = f\"Unpicklable_{type(value).__name__}\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_object(cls, obj):\n",
    "        return cls(obj)\n",
    "\n",
    "    def to_object(self):\n",
    "        # This is a placeholder. You might need to implement proper reconstruction logic.\n",
    "        return type(self.class_name, (), self.attributes)()\n",
    "\n",
    "def serialize_handle_object(obj):\n",
    "    return HandleWrapper.from_object(obj)\n",
    "\n",
    "def deserialize_handle_object(wrapped):\n",
    "    return wrapped.to_object()\n",
    "\n",
    "\n",
    "# # Register the custom serializers with Ray\n",
    "# ray.util.register_serializer(\n",
    "#     object,  # This will catch all objects\n",
    "#     serializer=lambda obj: serialize_handle_object(obj) if hasattr(obj, 'handle') or not cloudpickle.is_picklable(obj) else obj,\n",
    "#     deserializer=lambda obj: deserialize_handle_object(obj) if isinstance(obj, HandleWrapper) else obj\n",
    "# )\n",
    "\n",
    "ray.util.register_serializer(sqlite3.Connection, serializer=serialize_sqlite_connection, deserializer=deserialize_sqlite_connection)\n",
    "ray.util.register_serializer(type(threading.Lock), serializer=serialize_thread_lock, deserializer=deserialize_thread_lock)\n",
    "ray.util.register_serializer(hmac.HMAC, serializer=serialize_hmac, deserializer=deserialize_hmac)\n",
    "\n",
    "# Initialize Ray\n",
    "if not ray.is_initialized():\n",
    "    ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating Agent Framework with Email Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /teamspace/studios/this_studio/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import ray\n",
    "import json\n",
    "import uuid\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import daft\n",
    "from huggingface_hub import login\n",
    "from outlines import models, generate\n",
    "from outlines.models import VLLM\n",
    "from outlines.processors.structured import JSONLogitsProcessor\n",
    "from outlines.generate.api import GenerationParameters, SamplingParameters\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict\n",
    "from attrs import define, field\n",
    "from griptape.mixins import SerializableMixin, FuturesExecutorMixin\n",
    "from griptape.tasks import BaseTask\n",
    "from griptape.artifacts import TextArtifact\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv('.env')\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(token=hf_token)\n",
    "\n",
    "# Initialize Ray\n",
    "if not ray.is_initialized():\n",
    "    ray.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailModel(BaseModel):\n",
    "    sender: str = Field(..., description=\"Sender's email address\")\n",
    "    subject: str = Field(..., description=\"Subject of the email\")\n",
    "    content: str = Field(..., description=\"Content of the email\")\n",
    "    namespace: Optional[str] = Field(default=None, description=\"Namespace for the email\")\n",
    "    meta: Optional[str] = Field(default=None, description=\"Metadata for the email\")\n",
    "    vector: Optional[List[float]] = Field(default=None, description=\"Vector of content for the email\")\n",
    "\n",
    "class EmailListModel(BaseModel):\n",
    "    emails: List[EmailModel] = Field(..., description=\"List of emails\")\n",
    "\n",
    "class EmailEntryModel(BaseModel):\n",
    "    id: str = Field(..., description=\"Unique identifier for the email\")\n",
    "    sender: str = Field(..., description=\"Sender's email address\")\n",
    "    subject: str = Field(..., description=\"Subject of the email\")\n",
    "    content: str = Field(..., description=\"Content of the email\")\n",
    "    namespace: Optional[str] = Field(default=None, description=\"Namespace for the email\")\n",
    "    meta: Optional[str] = Field(default=None, description=\"Metadata for the email\")\n",
    "    vector: Optional[List[float]] = Field(default=None, description=\"Vectors of content for the email\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Agent Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from griptape.structures import Agent\n",
    "from lancedb.db import DBConnection\n",
    "import pandas as pd\n",
    "\n",
    "@define\n",
    "class EmailProcessingAgent(Agent):\n",
    "    lancedb_path: str = field(kw_only=True, default=\"lancedb_dir\", metadata={\"serializable\": True})\n",
    "    table_name: str = field(kw_only=True, default=\"emails\", metadata={\"serializable\": True})\n",
    "    model_name: str = field(kw_only=True, default=\"NousResearch/Meta-Llama-3.1-8B-Instruct\", metadata={\"serializable\": True})\n",
    "    max_model_len: int = field(kw_only=True, default=20000, metadata={\"serializable\": True})\n",
    "    vllm: VLLM = field(init=False)\n",
    "    lancedb: DBConnection = field(init=False)\n",
    "    \n",
    "    def __attrs_post_init__(self):\n",
    "        super().__attrs_post_init__()\n",
    "        self.lancedb = lancedb.connect(self.lancedb_path)\n",
    "        self.vllm = models.vllm(model_name=self.model_name, max_model_len=self.max_model_len)\n",
    "        \n",
    "        if self.table_name in self.lancedb.table_names():\n",
    "            self.lancedb.drop_table(self.table_name)\n",
    "        \n",
    "        schema = pa.schema([\n",
    "            pa.field('id', pa.string()),\n",
    "            pa.field('sender', pa.string()),\n",
    "            pa.field('subject', pa.string()),\n",
    "            pa.field('content', pa.string()),\n",
    "            pa.field('namespace', pa.string()),\n",
    "            pa.field('meta', pa.string()),\n",
    "            pa.field('vector', pa.list_(pa.float32()))\n",
    "        ])\n",
    "        table =self.lancedb.create_table(self.table_name, schema=schema)\n",
    "        \n",
    "        # Create FTS index\n",
    "        table.create_fts_index(['sender', 'subject', 'content'])\n",
    "\n",
    "\n",
    "    def process_email(self, email: EmailModel) -> EmailEntryModel:\n",
    "        prompt = f\"Summarize this Email: {email.dict()} using the following JSON schema: {EmailModel.schema_json()} Only respond with the JSON object.\\n\\n\"\n",
    "        \n",
    "        generation_parameters = GenerationParameters(max_tokens=4096, seed=42, stop_at=\"<|endoftext|>\")\n",
    "        logits_processor = JSONLogitsProcessor(\n",
    "            schema=EmailModel.schema(),\n",
    "            tokenizer=self.vllm.tokenizer,\n",
    "            whitespace_pattern=\"\\s+\")\n",
    "        sampling_parameters = SamplingParameters(temperature=1.0, sampler=\"nucleus\")\n",
    "        \n",
    "        response = self.vllm.generate(prompts=prompt, generation_parameters=generation_parameters, logits_processor=logits_processor, sampling_parameters=sampling_parameters)\n",
    "        \n",
    "        print(response)\n",
    "\n",
    "        try:\n",
    "            result = json.loads(response.lstrip().rstrip())\n",
    "            email.namespace = result.get(\"namespace\")\n",
    "            email.meta = json.dumps(result.get(\"metadata\", {}))\n",
    "        except json.JSONDecodeError:\n",
    "            email.namespace = \"unknown\"\n",
    "            email.meta = \"{}\"\n",
    "        \n",
    "        email_id = str(uuid.uuid5(uuid.NAMESPACE_OID, str(email.dict())))\n",
    "        return EmailEntryModel(id=email_id, **email.dict())\n",
    "\n",
    "    def upsert_email(self, email: EmailEntryModel):\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "        data_dict = email.model_dump()\n",
    "        pyarrow_table = pa.Table.from_pydict({k: [v] for k, v in data_dict.items()})\n",
    "        print(pyarrow_table)\n",
    "        table.add(pyarrow_table, mode=\"overwrite\")\n",
    "\n",
    "    def query_by_sender(self, sender: str, count: Optional[int] = None, namespace: Optional[str] = None) -> List[EmailEntryModel]:\n",
    "        table = self.lancedb.open_table(self.table_name)\n",
    "        query = table.search(f\"sender == '{sender}'\", vector_column_name=\"vector\")\n",
    "        \n",
    "        if namespace:\n",
    "            query = query.where(f\"namespace == '{namespace}'\")\n",
    "        \n",
    "        query = query.limit(count or 10)\n",
    "        results = query.to_pandas().to_dict(orient=\"records\")\n",
    "        print(results)\n",
    "        return [EmailEntryModel(**r) for r in results]\n",
    "\n",
    "@define\n",
    "class EmailWriteDataframeTask(BaseTask):\n",
    "    def __init__(self, lancedb_path: str):\n",
    "        super().__init__()\n",
    "        self.lancedb_path = lancedb_path\n",
    "        self.table_name = \"emails\"\n",
    "        daft.set_execution_config(enable_native_executor=True)  # Enable Ray execution\n",
    "        \n",
    "    def run(self, input_data: EmailListModel):\n",
    "        # Connect to LanceDB\n",
    "        db = lancedb.connect(self.lancedb_path)\n",
    "\n",
    "        # Prepare data\n",
    "        data = [\n",
    "            {\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"sender\": email.sender,\n",
    "                \"subject\": email.subject,\n",
    "                \"content\": email.content,\n",
    "                \"namespace\": email.namespace,\n",
    "                \"meta\": email.meta,\n",
    "                \"vector\": email.vector,\n",
    "                \"domain\": email.sender.split(\"@\")[-1],\n",
    "                \"word_count\": len(email.content.split())\n",
    "            }\n",
    "            for email in input_data.emails\n",
    "        ]\n",
    "\n",
    "        # Create or open the table\n",
    "        if self.table_name not in db.table_names():\n",
    "            table = db.create_table(self.table_name, data)\n",
    "        else:\n",
    "            table = db.open_table(self.table_name)\n",
    "            table.add(data)\n",
    "\n",
    "        # Convert to pandas DataFrame for display\n",
    "        result_df = pd.DataFrame(data)\n",
    "        print(result_df)\n",
    "        return TextArtifact(f\"Processed data:\\n{result_df}\")\n",
    "\n",
    "\n",
    "    def input(self) -> EmailListModel:\n",
    "        return EmailListModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Integrated Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id             sender         subject  \\\n",
      "0  3043f8b0-b0c1-404c-8c1f-3ac35c6ee1bb  alice@example.com         Meeting   \n",
      "1  8e2841b5-38be-4e8d-88f0-39120e57b11e    bob@example.org  Project Update   \n",
      "2  5d865537-62a3-4d78-8229-0aa29b93f483  carol@example.net         Invoice   \n",
      "\n",
      "                             content namespace             meta  \\\n",
      "0               Let's meet at 10 AM.  personal  location:office   \n",
      "1           The project is on track.      work  status:on track   \n",
      "2  Please find the invoice attached.      work   status:pending   \n",
      "\n",
      "            vector       domain  word_count  \n",
      "0  [0.1, 0.2, 0.3]  example.com           5  \n",
      "1  [0.4, 0.5, 0.6]  example.org           5  \n",
      "2  [0.7, 0.8, 0.9]  example.net           5  \n",
      "Processed data:\n",
      "                                     id             sender         subject  \\\n",
      "0  3043f8b0-b0c1-404c-8c1f-3ac35c6ee1bb  alice@example.com         Meeting   \n",
      "1  8e2841b5-38be-4e8d-88f0-39120e57b11e    bob@example.org  Project Update   \n",
      "2  5d865537-62a3-4d78-8229-0aa29b93f483  carol@example.net         Invoice   \n",
      "\n",
      "                             content namespace             meta  \\\n",
      "0               Let's meet at 10 AM.  personal  location:office   \n",
      "1           The project is on track.      work  status:on track   \n",
      "2  Please find the invoice attached.      work   status:pending   \n",
      "\n",
      "            vector       domain  word_count  \n",
      "0  [0.1, 0.2, 0.3]  example.com           5  \n",
      "1  [0.4, 0.5, 0.6]  example.org           5  \n",
      "2  [0.7, 0.8, 0.9]  example.net           5  \n",
      "INFO 09-04 18:30:32 llm_engine.py:184] Initializing an LLM engine (v0.5.5) with config: model='NousResearch/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='NousResearch/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=20000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=NousResearch/Meta-Llama-3.1-8B-Instruct, use_v2_block_manager=False, enable_prefix_caching=False)\n",
      "INFO 09-04 18:30:34 model_runner.py:879] Starting to load model NousResearch/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 09-04 18:30:34 weight_utils.py:236] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d63c87591b4f049ecab099cde84869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-04 18:30:39 model_runner.py:890] Loading model weights took 14.9888 GB\n",
      "INFO 09-04 18:30:45 gpu_executor.py:121] # GPU blocks: 1253, # CPU blocks: 2048\n",
      "INFO 09-04 18:30:48 model_runner.py:1181] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 09-04 18:30:48 model_runner.py:1185] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 09-04 18:31:15 model_runner.py:1300] Graph capturing finished in 26 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling FSM index for all state transitions: 100%|██████████| 148/148 [00:06<00:00, 22.69it/s]\n",
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.54s/it, est. speed input: 68.27 toks/s, output: 15.86 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sender\" : \"alice@example.com\"\n",
      "    , \"subject\" : \"Meeting\"\n",
      "    , \"content\" : \"Let\"\n",
      "    , \"namespace\" : null\n",
      "    , \"meta\" : \"location:office\"\n",
      "    , \"vector\" : [ 0.1, 0.2, 0.3 ]\n",
      "}\n",
      "pyarrow.Table\n",
      "id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: null\n",
      "meta: string\n",
      "vector: list<item: double>\n",
      "  child 0, item: double\n",
      "----\n",
      "id: [[\"3868b104-4797-54d6-8f51-85c8d9d43394\"]]\n",
      "sender: [[\"alice@example.com\"]]\n",
      "subject: [[\"Meeting\"]]\n",
      "content: [[\"Let's meet at 10 AM.\"]]\n",
      "namespace: [1 nulls]\n",
      "meta: [[\"{}\"]]\n",
      "vector: [[[0.1,0.2,0.3]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:05<00:00,  5.00s/it, est. speed input: 61.79 toks/s, output: 15.80 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sender\" : \"bob@example.org\"\n",
      "    , \"subject\" : \"Project Update\"\n",
      "    , \"content\" : \"The project is on track\"\n",
      "    , \"namespace\" : \"work\"\n",
      "    , \"meta\" : \"status:on track\"\n",
      "    , \"vector\" : [ 0.4, 0.5,  0.6 ]\n",
      "}\n",
      "pyarrow.Table\n",
      "id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: double>\n",
      "  child 0, item: double\n",
      "----\n",
      "id: [[\"d3757b5e-2c95-59ce-8ac5-1c4ea92f8abf\"]]\n",
      "sender: [[\"bob@example.org\"]]\n",
      "subject: [[\"Project Update\"]]\n",
      "content: [[\"The project is on track.\"]]\n",
      "namespace: [[\"work\"]]\n",
      "meta: [[\"{}\"]]\n",
      "vector: [[[0.4,0.5,0.6]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:04<00:00,  4.36s/it, est. speed input: 70.81 toks/s, output: 15.81 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"sender\" : \"carol@example.net\" ,\n",
      "    \"subject\" : \"Invoice\" ,\n",
      "    \"content\" : \"Please find the invoice attached.\" ,\n",
      "    \"namespace\" : \"work\" ,\n",
      "    \"meta\" : \"status:pending\" ,\n",
      "    \"vector\" : [ 0.7 ]  \n",
      "}\n",
      "pyarrow.Table\n",
      "id: string\n",
      "sender: string\n",
      "subject: string\n",
      "content: string\n",
      "namespace: string\n",
      "meta: string\n",
      "vector: list<item: double>\n",
      "  child 0, item: double\n",
      "----\n",
      "id: [[\"6e9f3d77-decd-51fd-a3c7-6cb86ecaaffa\"]]\n",
      "sender: [[\"carol@example.net\"]]\n",
      "subject: [[\"Invoice\"]]\n",
      "content: [[\"Please find the invoice attached.\"]]\n",
      "namespace: [[\"work\"]]\n",
      "meta: [[\"{}\"]]\n",
      "vector: [[[0.7,0.8,0.9]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example email data\n",
    "input_data = EmailListModel(emails=[\n",
    "    EmailModel(sender=\"alice@example.com\", subject=\"Meeting\", content=\"Let's meet at 10 AM.\", namespace=\"personal\", meta=\"location:office\", vector=[0.1, 0.2, 0.3]),\n",
    "    EmailModel(sender=\"bob@example.org\", subject=\"Project Update\", content=\"The project is on track.\", namespace=\"work\", meta=\"status:on track\", vector=[0.4, 0.5, 0.6]),\n",
    "    EmailModel(sender=\"carol@example.net\", subject=\"Invoice\", content=\"Please find the invoice attached.\", namespace=\"work\", meta=\"status:pending\", vector=[0.7, 0.8, 0.9])\n",
    "])\n",
    "\n",
    "# Initialize and run the workflow\n",
    "workflow = EmailWriteDataframeTask(lancedb_path=\"./lancedb_dir\")\n",
    "result_artifact = workflow.run(input_data=input_data)\n",
    "\n",
    "# Output the processed results\n",
    "print(result_artifact.value)\n",
    "\n",
    "processing_agent = EmailProcessingAgent(lancedb_path=\"./lancedb_dir\", table_name=\"emails\", model_name=\"NousResearch/Meta-Llama-3.1-8B-Instruct\", max_model_len=20000)\n",
    "\n",
    "processed_emails = []\n",
    "for email in input_data.emails:\n",
    "    processed_email = processing_agent.process_email(email)\n",
    "    processing_agent.upsert_email(processed_email)\n",
    "    processed_emails.append(processed_email)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Table email does not exist.Please first call db.create_table(email, data)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create the FTS index\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mlancedb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./lancedb_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memail\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m table\u001b[38;5;241m.\u001b[39mcreate_fts_index([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msender\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m], replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Add any other relevant fields\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Query emails by sender\u001b[39;00m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lancedb/db.py:445\u001b[0m, in \u001b[0;36mLanceDBConnection.open_table\u001b[0;34m(self, name, index_cache_size)\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_table\u001b[39m(\n\u001b[1;32m    432\u001b[0m     \u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, index_cache_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    433\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LanceTable:\n\u001b[1;32m    434\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Open a table in the database.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \n\u001b[1;32m    436\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    A LanceTable object representing the table.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLanceTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_cache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_cache_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/lancedb/table.py:937\u001b[0m, in \u001b[0;36mLanceTable.open\u001b[0;34m(cls, db, name, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m file_info \u001b[38;5;241m=\u001b[39m fs\u001b[38;5;241m.\u001b[39mget_file_info(path)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_info\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m!=\u001b[39m pa\u001b[38;5;241m.\u001b[39mfs\u001b[38;5;241m.\u001b[39mFileType\u001b[38;5;241m.\u001b[39mDirectory:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease first call db.create_table(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, data)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m     )\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tbl\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Table email does not exist.Please first call db.create_table(email, data)"
     ]
    }
   ],
   "source": [
    "# Create the FTS index\n",
    "table = lancedb.connect(\"./lancedb_dir\").open_table(\"emails\")\n",
    "table.create_fts_index(['sender', 'subject', 'content'], replace=True)  # Add any other relevant fields\n",
    "\n",
    "# Query emails by sender\n",
    "queried_emails = processing_agent.query_by_sender(sender=\"alice@example.com\", count=10, namespace=\"personal\")\n",
    "print(queried_emails)\n",
    "print(\"\\nQueried emails:\")\n",
    "for email in queried_emails:\n",
    "    print(f\"Sender: {email.sender}, Subject: {email.subject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
